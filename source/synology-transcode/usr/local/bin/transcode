#!/usr/bin/env python2.7

##############################################################################
# Helper functions
def file_hash(fname, block_size = 2**20):
  """Given the file name, returns a SHA-256 hash over the file contents"""
  with open(fname, 'rb') as f:
    import hashlib
    sha256 = hashlib.sha256()
    while True:
      data = f.read(block_size)
      if not data:
        break
      sha256.update(data)
    return sha256.hexdigest()


def read_hashes(path):
  """Reads file hashes from a .hashes file in the given directory and returns
     them."""
  import os.path
  hashname = os.path.join(path, '.hashes')
  hashes = {}
  import csv
  converted = False
  try:
    with open(hashname, 'rt') as hashfile:
      reader = csv.reader(hashfile)
      for row in reader:
        if len(row) > 2:
          hashes[row[0]] = (row[1], row[2])
        else:
          if row[1].startswith('('):
            # Workaround for messed up hash files
            tmp = row[1].strip('()').split(',')
            tmp = [t.strip('\'" ') for t in tmp]
            hashes[row[0]] = tuple(tmp)
            converted = True
          else:
            hashes[row[0]] = (row[1], None)
  except IOError as e:
    pass # no hash file/no hashes

  return hashes, converted


def write_hashes(path, hashes):
  """Writes file hashes to a .hashes file in the given directory."""
  import os.path
  hashname = os.path.join(path, '.hashes')
  import csv
  try:
    with open(hashname, 'wt') as hashfile:
      writer = csv.writer(hashfile)
      for row in hashes.items():
        towrite = [row[0]] + list(row[1])
        writer.writerow(towrite)
      hashfile.close()
  except IOError as e:
    return False
  return True


def normalize_meta(meta, files):
  """Given metadata from e.g. get_meta(), normalizes it - that is, it tries to
     detect which non-ID3v2.3 items are given and to convert them to ID3v2.3
     items if possible."""
  if 'track' in meta:
    track = meta['track']
    if track.find('/') < 0:
      track = int(track)
      total = 0
      try:
        total = meta['TOTALTRACKS']
      except KeyError:
        try:
          total = meta['TRACKTOTAL']
        except KeyError:
          total = len(files)
      meta['track'] = '%s/%s' % (track, total)

  return meta


def match_meta_pattern(meta, fname, pattern):
  """Tries to parse the given file name according to the given pattern, and
     provides the results in the meta dict."""
  # Ensure that the @(extension) is used correctly.
  if pattern.find('@(extension)') > 0 and not pattern.endswith('@(extension)'):
    raise RuntimeError('@(extension) may only appear at the end of file name patterns.')

  # First split the pattern into the number of components we need to recognize
  # independently.
  import re
  components = pattern.split('/')

  # Process components back to front; that way, if a component doesn't match,
  # we can still provide partial results
  known = [ 'artist', 'year', 'album', 'track', 'title' ]
  remainder = fname[:]
  while len(components):
    comp = components.pop()

    # Grab the last part of the filename, that's what we check this
    # component against.
    import os.path
    remainder, tail = os.path.split(remainder)

    # Try to match the current component against the file name's last part.
    import re
    res = re.search(comp, tail)
    if not res:
      break # no match, stop processing
    res = res.groupdict()

    # Add results to meta
    for key in known:
      if key in res and (key not in meta or not meta[key]):
        meta[key] = res[key]

  return meta


def get_meta(fname, pattern = None):
  """Extract audio metadata from the named file."""
  import subprocess, tempfile

  # Metadata from file name
  meta = {}
  if pattern:
    meta = match_meta_pattern(meta, fname, pattern)

  # Try to extract metadata. It may fail
  with tempfile.NamedTemporaryFile(mode = 'rt') as metafile:
    cmd = [
      'ffmpeg',
      '-i',
      fname,
      '-y',
      '-f',
      'ffmetadata',
      metafile.name,
    ]
    try:
      subprocess.check_output(cmd, stderr = subprocess.STDOUT)
    except subprocess.CalledProcessError as ex:
      return meta

    for row in metafile.readlines():
      row = row.split('=')
      if len(row) < 2:
        continue
      value = row[1].strip('\n')
      if value:
        meta[row[0]] = value

  return meta




##############################################################################
# File processing
def process(options):
  print options
  print normalize_meta(get_meta('01 - Lovelorn Rhapsody.mp3', options['metadata']), [])
  print normalize_meta(get_meta('01 - Lovelorn Rhapsody.wav', options['metadata']), [])
  print normalize_meta(get_meta('2003 - some album/01 - Lovelorn Rhapsody.wav', options['metadata']), [])
  print normalize_meta(get_meta('artist/2003 - some album/01 - Lovelorn Rhapsody.wav', options['metadata']), [])
  print normalize_meta(get_meta('/some/prefix/artist/2003 - some album/01 - Lovelorn Rhapsody.wav', options['metadata']), [])

##############################################################################
# Main entry point
def main():
  DEFAULTS = {
    'include': ['*.flac', '*.wav'],
    'exclude': ['@eaDir'],
    'metadata': r'(?P<artist>.+)/(?P<year>[^- ]+) *- *(?P<album>.+)/(?P<track>[^- ]+) *- *(?P<title>.+)\..*',
  }

  import argparse
  parser = argparse.ArgumentParser(
      description = 'Transcode high quality audio files automatically to mp3',
      epilog = """Include and exclude patterns are shell style patterns. See
the shell documentation or the Python `fnmatch` module documentation for
details.

Processing is limited to files that are in the source directories, are matched
by one of the include patterns, and are not matched by one of the exclude
patterns.

Include patterns are applied to the full file path name, but exclude patterns
are also applied to full directory path names, to more easily exclude an entire
sub directory tree.
"""
  )

  parser.add_argument('destination', metavar = 'DST', type = str, nargs = 1,
      help = 'Directory in which to store processed files.')
  parser.add_argument('sources', metavar = 'SRC', type = str, nargs = '+',
      help = 'Directory with source files.')

  parser.add_argument('-c', '--config', metavar = 'FILE', type = str,
      default = '/etc/transcode.cfg',
      help = 'Location of the configuration file. Defaults to `/etc/transcode.cfg`.')

  parser.add_argument('-i', '--include', metavar = 'PATTERN', type = str,
      action = 'append',
      help = 'Include patterns for source filenames to process. Defaults to `*.flac` and `*.wav`.')
  parser.add_argument('-e', '--exclude', metavar = 'PATTERN', type = str,
      action = 'append',
      help = 'Exclude patterns for source filenames or directories. Defaults to `@eaDir` for directories.')

  parser.add_argument('-w', '--watch', action = 'store_const', const = True,
      default = False,
      help = 'Instead of processing the source directories once and exiting, keep running and watch them for file additions and changes to process.')


  parser.add_argument('--version', action = 'version', version = '%(prog)s 0.2')

  args = vars(parser.parse_args())
  for k, v in args.items():
    if v is None:
      del(args[k])

  # Try processing config file, if it exists.
  import ConfigParser
  parser = ConfigParser.SafeConfigParser()
  try:
    parser.read(args['config'])
  except ConfigParser.ParsingError as err:
    import sys
    sys.stderr.write('ERROR %s\n' % err)
    sys.exit(1)

  mapping = {
    'destination': ('directories', 'destination'),
    'sources': ('directories', 'sources'),
    'include': ('filters', 'include'),
    'exclude': ('filters', 'exclude'),
    'metadata': ('filters', 'metadata', False),
  }
  options = DEFAULTS
  for key, source in mapping.items():
    if parser.has_section(source[0]) and parser.has_option(source[0], source[1]):
      value = parser.get(source[0], source[1])
      if len(source) > 2 and not source[2]:
        value = value.strip()
        if value.startswith('"') and value.endswith('"'):
          value = value.strip('"')
        options[key] = value
      else:
        import re
        values = re.findall(r'(?:"[^"]*"|[^\s"])+', value)
        def unquote(item):
          if item.startswith('"') and item.endswith('"'):
            return item.strip('"')
          return item
        values = map(unquote, values)
        options[key] = values

  # Now merge command line arguments, they override the config file
  # options
  options.update(args);

  # Make the include/exclude patterns useful
  import re, fnmatch
  options['include'] = r'|'.join([fnmatch.translate(x) for x in options['include']])
  options['exclude'] = r'|'.join([fnmatch.translate(x) for x in options['exclude']]) or r'$.'

  # Let's do this thing!
  process(options)


if '__main__' == __name__:
  main()
