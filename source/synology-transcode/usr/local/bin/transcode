#!/usr/bin/env python2.7

##############################################################################
# Helper functions
def file_hash(fname, block_size = 2**20):
  """Given the file name, returns a SHA-256 hash over the file contents"""
  with open(fname, 'rb') as f:
    import hashlib
    sha256 = hashlib.sha256()
    while True:
      data = f.read(block_size)
      if not data:
        break
      sha256.update(data)
    return sha256.hexdigest()


def read_hashes(path):
  """Reads file hashes from a .hashes file in the given directory and returns
     them."""
  import os.path
  hashname = os.path.join(path, '.hashes')
  hashes = {}
  import csv
  converted = False
  try:
    with open(hashname, 'rt') as hashfile:
      reader = csv.reader(hashfile)
      for row in reader:
        if len(row) > 2:
          hashes[row[0]] = (row[1], row[2])
        else:
          if row[1].startswith('('):
            # Workaround for messed up hash files
            tmp = row[1].strip('()').split(',')
            tmp = [t.strip('\'" ') for t in tmp]
            hashes[row[0]] = tuple(tmp)
            converted = True
          else:
            hashes[row[0]] = (row[1], None)
  except IOError as e:
    pass # no hash file/no hashes

  return hashes, converted


def write_hashes(path, hashes):
  """Writes file hashes to a .hashes file in the given directory."""
  import os.path
  hashname = os.path.join(path, '.hashes')
  import csv
  try:
    with open(hashname, 'wt') as hashfile:
      writer = csv.writer(hashfile)
      for row in hashes.items():
        towrite = [row[0]] + list(row[1])
        writer.writerow(towrite)
      hashfile.close()
  except IOError as e:
    print('ERROR', e)


def get_meta(fname):
  """Extract audio metadata from the named file."""
  import subprocess

  cmd = [
    'ffmpeg',
    '-i',
    fname,
    '-y',
    '-f',
    'ffmetadata',
    '/tmp/transcode-meta',
  ]
  ret = subprocess.call(cmd)
  print('ret', ret)
  if ret != 0:
    return {}

  meta = {}
  with open('/tmp/transcode-meta', 'rt') as metafile:
    for row in metafile.readlines():
      row = row.split('=')
      if len(row) < 2:
        continue
      meta[row[0]] = row[1].strip('\n')
  return meta



##############################################################################
# File processing
def process(options):
  print options

##############################################################################
# Main entry point
def main():
  DEFAULTS = {
    'include': ['*.flac', '*.wav'],
    'exclude': ['@eaDir'],
  }

  import argparse
  parser = argparse.ArgumentParser(
      description = 'Transcode high quality audio files automatically to mp3',
      epilog = """Include and exclude patterns are shell style patterns. See
the shell documentation or the Python `fnmatch` module documentation for
details.

Processing is limited to files that are in the source directories, are matched
by one of the include patterns, and are not matched by one of the exclude
patterns.

Include patterns are applied to the full file path name, but exclude patterns
are also applied to full directory path names, to more easily exclude an entire
sub directory tree.
"""
  )

  parser.add_argument('destination', metavar = 'DST', type = str, nargs = 1,
      help = 'Directory in which to store processed files.')
  parser.add_argument('sources', metavar = 'SRC', type = str, nargs = '+',
      help = 'Directory with source files.')

  parser.add_argument('-c', '--config', metavar = 'FILE', type = str,
      default = '/etc/transcode.cfg',
      help = 'Location of the configuration file. Defaults to `/etc/transcode.cfg`.')

  parser.add_argument('-i', '--include', metavar = 'PATTERN', type = str,
      action = 'append',
      help = 'Include patterns for source filenames to process. Defaults to `*.flac` and `*.wav`.')
  parser.add_argument('-e', '--exclude', metavar = 'PATTERN', type = str,
      action = 'append',
      help = 'Exclude patterns for source filenames or directories. Defaults to `@eaDir` for directories.')

  parser.add_argument('-w', '--watch', action = 'store_const', const = True,
      default = False,
      help = 'Instead of processing the source directories once and exiting, keep running and watch them for file additions and changes to process.')


  parser.add_argument('--version', action = 'version', version = '%(prog)s 0.2')

  args = vars(parser.parse_args())
  for k, v in args.items():
    if v is None:
      del(args[k])

  # Try processing config file, if it exists.
  import ConfigParser
  parser = ConfigParser.SafeConfigParser()
  try:
    parser.read(args['config'])
  except ConfigParser.ParsingError as err:
    import sys
    sys.stderr.write('ERROR %s\n' % err)
    sys.exit(1)

  mapping = {
    'destination': ('directories', 'destination'),
    'sources': ('directories', 'sources'),
    'include': ('filters', 'include'),
    'exclude': ('filters', 'exclude'),
  }
  options = DEFAULTS
  for key, path in mapping.items():
    if parser.has_section(path[0]) and parser.has_option(path[0], path[1]):
      import re
      values = re.findall(r'(?:"[^"]*"|[^\s"])+', parser.get(path[0], path[1]))
      def unquote(item):
        if item.startswith('"') and item.endswith('"'):
          return item.strip('"')
        return item
      values = map(unquote, values)
      options[key] = values

  # Now merge command line arguments, they override the config file
  # options
  options.update(args);

  # Make the include/exclude patterns useful
  import re, fnmatch
  options['include'] = r'|'.join([fnmatch.translate(x) for x in options['include']])
  options['exclude'] = r'|'.join([fnmatch.translate(x) for x in options['exclude']]) or r'$.'

  # Let's do this thing!
  process(options)


if '__main__' == __name__:
  main()
