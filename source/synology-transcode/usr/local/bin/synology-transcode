#!/usr/bin/env python3

import configparser, os.path
parser = configparser.SafeConfigParser()
parser.read(['.synology-transcode', os.path.expanduser('~/.synology-transcode')])

SOURCES = []
TARGET = None
TARGET_EXT = '.mp3'
INCLUDES = [ '*.flac', '*.wav' ]
EXCLUDES = [ '@eaDir' ]

import sys

try:
  SOURCES = [d.strip() for d in parser.get('directories', 'sources').split('\n')]
  TARGET = parser.get('directories', 'target').strip()
except (configparser.NoSectionError, configparser.NoOptionError) as ex:
  sys.stderr.write('Could not read configuration: %s\n' % ex)
  sys.exit(1)

try:
  INCLUDES = [p.strip() for p in parser.get('filter', 'includes').split(' ')]
except (configparser.NoSectionError, configparser.NoOptionError) as ex:
  pass

try:
  EXCLUDES = [p.strip() for p in parser.get('filter', 'excludes').split(' ')]
except (configparser.NoSectionError, configparser.NoOptionError) as ex:
  pass

import re, fnmatch

INCLUDES = r'|'.join([fnmatch.translate(x) for x in INCLUDES])
EXCLUDES = r'|'.join([fnmatch.translate(x) for x in EXCLUDES]) or r'$.'

def file_hash(fname, block_size = 2**20):
  with open(fname, 'rb') as f:
    import hashlib
    sha256 = hashlib.sha256()
    while True:
      data = f.read(block_size)
      if not data:
        break
      sha256.update(data)
    return sha256.hexdigest()


def read_hashes(path):
  import os.path
  hashname = os.path.join(path, '.hashes')
  hashes = {}
  import csv  
  converted = False
  try:  
    with open(hashname, 'rt', encoding='utf8') as hashfile:  
      reader = csv.reader(hashfile)
      for row in reader:
        if len(row) > 2:
          hashes[row[0]] = (row[1], row[2])
        else:
          if row[1].startswith('('):
            # Workaround for messed up hash files
            tmp = row[1].strip('()').split(',') 
            tmp = [t.strip('\'" ') for t in tmp]
            hashes[row[0]] = tuple(tmp)
            converted = True
          else:
            hashes[row[0]] = (row[1], None)
  except IOError as e:
    pass # no hash file/no hashes
    
  return hashes, converted
  
  
def write_hashes(path, hashes):
  import os.path
  hashname = os.path.join(path, '.hashes')
  import csv  
  try:
    with open(hashname, 'wt', encoding='utf8') as hashfile:
      writer = csv.writer(hashfile)
      for row in hashes.items():
        towrite = [row[0]] + list(row[1])
        writer.writerow(towrite)
      hashfile.close()
  except IOError as e:
    print('ERROR', e)
    
    
def get_meta(fname):
  import subprocess
  
  cmd = [
    'ffmpeg',
    '-i',
    fname,
    '-y',
    '-f',
    'ffmetadata',
    '/tmp/transcode-meta',
  ]
  ret = subprocess.call(cmd)
  print('ret', ret)
  if ret != 0:
    return {}
  
  meta = {}
  with open('/tmp/transcode-meta', 'rt', encoding='utf8') as metafile:
    for row in metafile.readlines():
      row = row.split('=')
      if len(row) < 2:
      	continue
      meta[row[0]] = row[1].strip('\n') 
  return meta
  
  
for source in SOURCES:
  import os, os.path
  for root, dirs, files in os.walk(source):
    # Filter out unwanted directories
    dirs[:] = [d for d in dirs if not re.match(EXCLUDES, d, re.IGNORECASE)]

    # Filter out unwanted files
    files[:] = [f for f in files if not re.match(EXCLUDES, f, re.IGNORECASE)]
    files[:] = [f for f in files if re.match(INCLUDES, f, re.IGNORECASE)]

    if not files:
      continue
    
    dirs.sort()
    files.sort()

    # Split root to get Artist, Album
    base, album = os.path.split(root)
    base, artist = os.path.split(base)

    # Target directory
    newdir = os.path.join(TARGET, artist, album)

    # Try to read hashes of source files. We consider a file processed if it's
    # hash is recorded here and hasn't changed.
    hashes, converted = read_hashes(newdir)
    if converted:
      write_hashes(newdir, hashes)

    # Process files
    for fname in files:
      basename, ext = os.path.splitext(fname)

      fullpath = os.path.join(base, artist, album, fname)
      newfname = os.path.join(newdir, basename) + TARGET_EXT

      newhash = file_hash(fullpath)
    
      print(fullpath, '->', newfname)
    
      # Old hashes
      if fname in hashes:
        # File was processed, let's leave it at that
        if hashes[fname][0] == newhash:
          print(' -> updating to new style hash')
          del(hashes[fname])
          hashes[basename] = (newhash, fname)
          write_hashes(newdir, hashes)
          continue
      
      # New hashes
      if basename in hashes:
        if hashes[basename][0] == newhash:
          print(' -> source already processed, skipping')
          continue
        elif hashes[basename[1]] == fname:
          print(' -> source updated, processing')
        else:
          print(' -> target exists from other source, skipping')
          continue
      else:
        print(' -> processing')

      # Create directory
      try:
        os.makedirs(newdir)
      except OSError as e:
        pass # path exists

      # Extract some extra metadata
      meta = get_meta(fullpath)
      track = meta['track']
      tracks = 0
      try:
        tracks = meta['TOTALTRACKS']
      except KeyError:
        try:
          tracks = meta['TRACKTOTAL']
        except KeyError:
          tracks = len(files)

      # Run ffmpeg
      cmd = [
        'ffmpeg',
        '-y',
        '-i',
        fullpath,
        '-acodec',
        'libmp3lame',
        '-aq',
        '0',
        '-map_metadata',
        '0',
        '-id3v2_version',
        '3',
        '-metadata',
        'track=%s/%s' % (track, tracks),
        newfname
      ]
      
      import subprocess
      ret = subprocess.call(cmd)
      if 0 == ret:
        hashes[basename] = (newhash, fname)
        write_hashes(newdir, hashes)

